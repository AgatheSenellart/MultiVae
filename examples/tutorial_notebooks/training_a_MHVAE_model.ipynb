{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a MHVAE model on PolyMNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we demonstrate how to define and train a MHVAE model on PolyMNIST. \n",
    "\n",
    "We refer to the following diagram for setting architectures: \n",
    "\n",
    "![image](../../docs/source/models/multimodal_vaes/mhvae_architectures.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"/home/asenella/data\"\n",
    "# First import the dataset class\n",
    "from multivae.data.datasets import MMNISTDataset\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "train_set = MMNISTDataset(DATA_PATH)\n",
    "train_set, eval_set = random_split(train_set, [0.8, 0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to define the architectures we are going to use. \n",
    "\n",
    "Here we use 2 levels of latent variables. We use the same architectures for all modalities. \n",
    "Each bottom-up blocks and top-down blocks are convolutional networks. \n",
    "We keep track of the input dims and output dims of each module below to make sure they match. \n",
    "\n",
    "latent_dim = 32\n",
    "\n",
    "|block | input_dim | output_dim |\n",
    "|-----|------------|------------|\n",
    "|encoder|(3,28,28)| (32,14,14)  |\n",
    "|bottom-up_1 | (32,14,14)|(64,7,7)|\n",
    "|bottom-up_2 | (64,7,7)|latent_dim|\n",
    "|top-down_2 |latent_dim|(64,7,7)|\n",
    "|top-down_1 |(64,7,7)|(32,14,14)|\n",
    "|decoder|(32,14,14)|(3,28,28)|\n",
    "|prior_block_2|(64,7,7)|(64,7,7)|\n",
    "|prior_block_1|(32,14,14)|(32,14,14)|\n",
    "|posterior_block_2|(2*64,7,7)|(64,7,7)|\n",
    "|posterior_block_1|(2*32,14,14)|(32,14,14)|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multivae.models.mhvae import MHVAEConfig, MHVAE\n",
    "\n",
    "# Define the model configuration\n",
    "model_config = MHVAEConfig(\n",
    "    n_modalities=5,\n",
    "    latent_dim=64,\n",
    "    input_dims={f\"m{i}\": (3, 28, 28) for i in range(5)},\n",
    "    n_latent=3,\n",
    "    beta=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multivae.models.base import BaseEncoder, ModelOutput, BaseDecoder\n",
    "from torch import nn\n",
    "\n",
    "# Defining encoder and bottom-up blocks\n",
    "\n",
    "\n",
    "class my_input_encoder(BaseEncoder):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv0 = nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1, bias=True)\n",
    "        self.act_1 = nn.SiLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv0(x)\n",
    "        x = self.act_1(x)\n",
    "\n",
    "        return ModelOutput(embedding=x)\n",
    "\n",
    "\n",
    "bu_1 = nn.Sequential(\n",
    "    nn.Conv2d(\n",
    "        in_channels=32, out_channels=64, kernel_size=3, stride=2, padding=1, bias=True\n",
    "    ),\n",
    "    nn.SiLU(),\n",
    ")\n",
    "\n",
    "\n",
    "class bu_2(BaseEncoder):\n",
    "    def __init__(self, inchannels, outchannels, latent_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=inchannels,\n",
    "                out_channels=outchannels,\n",
    "                kernel_size=3,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "                bias=True,\n",
    "            ),\n",
    "            nn.SiLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(2048, 512),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.mu = nn.Linear(512, latent_dim)\n",
    "        self.log_var = nn.Linear(512, latent_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.network(x)\n",
    "        return ModelOutput(embedding=self.mu(h), log_covariance=self.log_var(h))\n",
    "\n",
    "\n",
    "# Defininin top-down blocks and decoder\n",
    "\n",
    "\n",
    "class td_2(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear = nn.Sequential(nn.Linear(latent_dim, 2048), nn.ReLU())\n",
    "        self.convs = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, bias=True),\n",
    "            nn.SiLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.linear(x)\n",
    "        h = h.view(h.shape[0], 128, 4, 4)\n",
    "        return self.convs(h)\n",
    "\n",
    "\n",
    "td_1 = nn.Sequential(\n",
    "    nn.ConvTranspose2d(\n",
    "        64, 32, kernel_size=3, stride=2, padding=1, output_padding=1, bias=True\n",
    "    ),\n",
    "    nn.SiLU(),\n",
    ")\n",
    "\n",
    "\n",
    "class my_input_decoder(BaseDecoder):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.network = nn.Sequential(\n",
    "            nn.ConvTranspose2d(32, 32, 3, 2, 1, output_padding=1),\n",
    "            nn.SiLU(),\n",
    "            nn.ConvTranspose2d(32, 3, 3, 1, 1, output_padding=0),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return ModelOutput(reconstruction=self.network(x))\n",
    "\n",
    "\n",
    "# Defining prior blocks and posterior blocks\n",
    "\n",
    "\n",
    "class prior_block(BaseEncoder):\n",
    "    def __init__(self, n_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.mu = nn.utils.parametrizations.weight_norm(\n",
    "            nn.Conv2d(n_channels, n_channels, 1, 1, 0)\n",
    "        )\n",
    "        self.logvar = nn.utils.parametrizations.weight_norm(\n",
    "            nn.Conv2d(n_channels, n_channels, 1, 1, 0)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return ModelOutput(embedding=self.mu(x), log_covariance=self.logvar(x))\n",
    "\n",
    "\n",
    "class posterior_block(BaseEncoder):\n",
    "    def __init__(self, n_channels_before_concat):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                2 * n_channels_before_concat,\n",
    "                n_channels_before_concat,\n",
    "                3,\n",
    "                1,\n",
    "                1,\n",
    "                bias=True,\n",
    "            ),\n",
    "            nn.SiLU(),\n",
    "        )\n",
    "\n",
    "        self.mu = nn.utils.parametrizations.weight_norm(\n",
    "            nn.Conv2d(n_channels_before_concat, n_channels_before_concat, 1, 1, 0)\n",
    "        )\n",
    "        self.logvar = nn.utils.parametrizations.weight_norm(\n",
    "            nn.Conv2d(n_channels_before_concat, n_channels_before_concat, 1, 1, 0)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.network(x)\n",
    "        return ModelOutput(embedding=self.mu(h), log_covariance=self.logvar(h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Shared weights for the posterior blocks\n"
     ]
    }
   ],
   "source": [
    "model = MHVAE(\n",
    "    model_config=model_config,\n",
    "    encoders={f\"m{i}\": my_input_encoder() for i in range(5)},\n",
    "    decoders={f\"m{i}\": my_input_decoder() for i in range(5)},\n",
    "    bottom_up_blocks={\n",
    "        f\"m{i}\": [bu_1, bu_2(64, 128, model_config.latent_dim)] for i in range(5)\n",
    "    },\n",
    "    top_down_blocks=[td_1, td_2(model_config.latent_dim)],\n",
    "    prior_blocks=[prior_block(32), prior_block(64)],\n",
    "    posterior_blocks=[posterior_block(32), posterior_block(64)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelOutput([('loss', tensor(139578.3594, grad_fn=<MeanBackward0>)),\n",
       "             ('loss_sum', tensor(139578.3594, grad_fn=<MeanBackward0>)),\n",
       "             ('metrics',\n",
       "              {'kl_3': tensor(306.9045, grad_fn=<SumBackward0>),\n",
       "               'kl_2': tensor(15249.9697, grad_fn=<SumBackward0>),\n",
       "               'kl_1': tensor(30313.1875, grad_fn=<SumBackward0>)})])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that the data compiles by running a forward pass\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dl = DataLoader(train_set, 10)\n",
    "sample = next(iter(dl))\n",
    "model(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multivae.trainers import BaseTrainer, BaseTrainerConfig\n",
    "\n",
    "\n",
    "trainer_config = BaseTrainerConfig(\n",
    "    output_dir=\"~/experiments/mhvae_test\",\n",
    "    per_device_eval_batch_size=64,\n",
    "    per_device_train_batch_size=64,\n",
    "    num_epochs=20,\n",
    "    steps_predict=1,\n",
    "    learning_rate=1e-3,\n",
    ")\n",
    "\n",
    "## Set up wandb callback\n",
    "# wandb_cb = WandbCallback()\n",
    "# wandb_cb.setup(trainer_config,model_config,'mhvae_test')\n",
    "\n",
    "\n",
    "trainer = BaseTrainer(\n",
    "    training_config=trainer_config,\n",
    "    model=model,\n",
    "    train_dataset=train_set,\n",
    "    eval_dataset=eval_set,\n",
    "    #   callbacks=[wandb_cb]\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multivaenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
