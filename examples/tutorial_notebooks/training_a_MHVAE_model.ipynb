{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a MHVAE model on PolyMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /home/agathe/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from multivae.data.datasets import MMNISTDataset\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "train_set = MMNISTDataset('~/data')\n",
    "train_set, eval_set = random_split(train_set, [0.8,0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to define the architectures we are going to use. \n",
    "\n",
    "Here we use 2 levels of latent variables. We use the same architectures for all modalities. \n",
    "\n",
    "latent_dim = 32\n",
    "\n",
    "|block | input_dim | output_dim |\n",
    "|-----|------------|------------|\n",
    "|encoder|(3,28,28)| (32,14,14)  |\n",
    "|bottom-up_1 | (32,14,14)|(64,7,7)|\n",
    "|bottom-up_2 | (64,7,7)|latent_dim|\n",
    "|top-down_2 |latent_dim|(64,7,7)|\n",
    "|top-down_1 |(64,7,7)|(32,14,14)|\n",
    "|decoder|(32,14,14)|(3,28,28)|\n",
    "|prior_block_2|(64,7,7)|(64,7,7)|\n",
    "|prior_block_1|(32,14,14)|(32,14,14)|\n",
    "|posterior_block_2|(2*64,7,7)|(64,7,7)|\n",
    "|posterior_block_1|(2*32,14,14)|(32,14,14)|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multivae.models.mhvae import MHVAEConfig, MHVAE\n",
    "\n",
    "model_config = MHVAEConfig(\n",
    "    n_modalities=5,\n",
    "    latent_dim=64,\n",
    "    input_dims={f'm{i}':(3,28,28) for i in range(5)},\n",
    "    n_latent=3,\n",
    "    beta=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multivae.models.base import BaseEncoder, ModelOutput, BaseDecoder\n",
    "from torch import nn\n",
    "\n",
    "# Defining encoder and bottom-up blocks\n",
    "\n",
    "class my_input_encoder(BaseEncoder):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv0 = nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1, bias=True)\n",
    "        self.act_1 = nn.SiLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "       \n",
    "        x = self.conv0(x)\n",
    "        x = self.act_1(x)\n",
    "        \n",
    "        return ModelOutput(embedding = x)\n",
    "\n",
    "\n",
    "bu_1 = nn.Sequential(nn.Conv2d(\n",
    "            in_channels=32,\n",
    "            out_channels=64,\n",
    "            kernel_size=3,\n",
    "            stride=2,\n",
    "            padding=1,\n",
    "            bias=True\n",
    "        ) , nn.SiLU())\n",
    "\n",
    "        \n",
    "class bu_2(BaseEncoder):\n",
    "    \n",
    "    def __init__(self, inchannels,outchannels,latent_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.network = nn.Sequential( nn.Conv2d(\n",
    "            in_channels=inchannels,\n",
    "            out_channels=outchannels,\n",
    "            kernel_size=3,\n",
    "            stride=2,\n",
    "            padding=1,\n",
    "            bias=True\n",
    "        ) ,\n",
    "        nn.SiLU(),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(2048, 512),  \n",
    "        nn.ReLU())\n",
    "        \n",
    "        self.mu = nn.Linear(512, latent_dim)\n",
    "        self.log_var = nn.Linear(512, latent_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h = self.network(x)\n",
    "        return ModelOutput(\n",
    "            embedding = self.mu(h),\n",
    "            log_covariance = self.log_var(h)\n",
    "        )\n",
    "        \n",
    "# Defininin top-down blocks and decoder\n",
    "        \n",
    "class td_2(nn.Module):\n",
    "    \n",
    "    def __init__(self, latent_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        \n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(latent_dim,2048),nn.ReLU()\n",
    "        )\n",
    "        self.convs = nn.Sequential(nn.ConvTranspose2d(128,64,kernel_size=3,stride=2,padding=1,bias=True),\n",
    "                                   nn.SiLU())\n",
    "    def forward(self,x):\n",
    "        h=self.linear(x)\n",
    "        h = h.view(h.shape[0],128,4,4)\n",
    "        return self.convs(h)\n",
    "    \n",
    "td_1 = nn.Sequential(\n",
    "    nn.ConvTranspose2d(64,32,kernel_size=3,stride=2,padding=1, output_padding=1,bias=True),\n",
    "                                   nn.SiLU()\n",
    ")\n",
    "\n",
    "class my_input_decoder(BaseDecoder):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.network = nn.Sequential(\n",
    "            nn.ConvTranspose2d(32,32,3,2,1, output_padding=1),nn.SiLU(),\n",
    "            nn.ConvTranspose2d(32,3,3,1,1, output_padding=0),nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return ModelOutput(\n",
    "            reconstruction = self.network(x)\n",
    "        )\n",
    "        \n",
    "# Defining prior blocks and posterior blocks\n",
    "\n",
    "class prior_block(BaseEncoder):\n",
    "    \n",
    "    def __init__(self, n_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.mu = nn.utils.parametrizations.weight_norm(nn.Conv2d(n_channels,n_channels,1,1,0))\n",
    "        self.logvar = nn.utils.parametrizations.weight_norm(nn.Conv2d(n_channels,n_channels,1,1,0))\n",
    "    def forward(self, x):\n",
    "        return ModelOutput(embedding = self.mu(x), log_covariance = self.logvar(x))\n",
    "\n",
    "class posterior_block(BaseEncoder):\n",
    "    \n",
    "    def __init__(self, n_channels_before_concat):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(2*n_channels_before_concat,n_channels_before_concat,3,1,1, bias=True), \n",
    "            nn.SiLU()\n",
    "        )\n",
    "        \n",
    "        self.mu = nn.utils.parametrizations.weight_norm(nn.Conv2d(n_channels_before_concat,n_channels_before_concat,1,1,0))\n",
    "        self.logvar = nn.utils.parametrizations.weight_norm(nn.Conv2d(n_channels_before_concat,n_channels_before_concat,1,1,0))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h = self.network(x)\n",
    "        return ModelOutput(embedding = self.mu(h), log_covariance = self.logvar(h))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MHVAE(\n",
    "    model_config=model_config,\n",
    "    encoders = {f'm{i}' : my_input_encoder() for i in range(5)},\n",
    "    decoders = {f'm{i}':my_input_decoder() for i in range(5)},\n",
    "    bottom_up_blocks={f'm{i}' : [bu_1,bu_2(64,128,model_config.latent_dim)] for i in range(5)},\n",
    "    top_down_blocks=[td_1,td_2(model_config.latent_dim)],\n",
    "    prior_blocks=[prior_block(32), prior_block(64)],\n",
    "    posterior_blocks=[posterior_block(32),posterior_block(64)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelOutput([('loss', tensor(138870.2188, grad_fn=<MeanBackward0>)),\n",
       "             ('loss_sum', tensor(138870.2188, grad_fn=<MeanBackward0>)),\n",
       "             ('metrics',\n",
       "              {'kl_3': tensor(307.2871, grad_fn=<SumBackward0>),\n",
       "               'kl_2': tensor(15209.9375, grad_fn=<SumBackward0>),\n",
       "               'kl_1': tensor(30374.2695, grad_fn=<SumBackward0>)})])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dl = DataLoader(train_set,10)\n",
    "\n",
    "sample =next(iter(dl))\n",
    "\n",
    "model(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model passed sanity check !\n",
      "Ready for training.\n",
      "\n",
      "Setting the optimizer with learning rate 0.001\n",
      "Created ~/experiments/mhvae_test/MHVAE_training_2025-01-23_16-14-38. \n",
      "Training config, checkpoints and final model will be saved here.\n",
      "\n",
      "Training params:\n",
      " - max_epochs: 20\n",
      " - per_device_train_batch_size: 64\n",
      " - per_device_eval_batch_size: 64\n",
      " - checkpoint saving every: None\n",
      "Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Scheduler: None\n",
      "\n",
      "Successfully launched training !\n",
      "\n",
      "Training of epoch 1/20:  15%|█▌        | 113/750 [00:36<03:32,  2.99batch/s]/home/agathe/dev/multivae_package/MultiVae/src/multivae/models/base/base_ae_model.py:404: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  \"\"\"Compute the conditional likelihoods ln p(x|y) , ln p(y|x) with MonteCarlo Sampling and the approximation :\n",
      "/home/agathe/dev/multivae_package/MultiVae/src/multivae/models/base/base_ae_model.py:483: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  \"\"\"\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 26\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# wandb_cb = WandbCallback()\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# wandb_cb.setup(trainer_config,model_config,'mhvae_test')\u001b[39;00m\n\u001b[1;32m     19\u001b[0m trainer \u001b[38;5;241m=\u001b[39m BaseTrainer(training_config\u001b[38;5;241m=\u001b[39mtrainer_config,\n\u001b[1;32m     20\u001b[0m                       model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     21\u001b[0m                       train_dataset\u001b[38;5;241m=\u001b[39mtrain_set,\n\u001b[1;32m     22\u001b[0m                       eval_dataset\u001b[38;5;241m=\u001b[39meval_set,\n\u001b[1;32m     23\u001b[0m                     \u001b[38;5;66;03m#   callbacks=[wandb_cb]\u001b[39;00m\n\u001b[1;32m     24\u001b[0m                       )\n\u001b[0;32m---> 26\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/multivae_package/MultiVae/src/multivae/trainers/base/base_trainer.py:484\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[0;34m(self, log_output_dir)\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_epoch_begin(\n\u001b[1;32m    476\u001b[0m     training_config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_config,\n\u001b[1;32m    477\u001b[0m     epoch\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m    478\u001b[0m     train_loader\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loader,\n\u001b[1;32m    479\u001b[0m     eval_loader\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval_loader,\n\u001b[1;32m    480\u001b[0m )\n\u001b[1;32m    481\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_train_loss, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_eval_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_train_step(\n\u001b[1;32m    482\u001b[0m     epoch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_train_loss, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_eval_loss\n\u001b[1;32m    483\u001b[0m )\n\u001b[0;32m--> 484\u001b[0m epoch_train_loss, epoch_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    485\u001b[0m metrics \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m k: epoch_metrics[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m epoch_metrics}\n\u001b[1;32m    486\u001b[0m metrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_epoch_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m epoch_train_loss\n",
      "File \u001b[0;32m~/dev/multivae_package/MultiVae/src/multivae/trainers/base/base_trainer.py:663\u001b[0m, in \u001b[0;36mBaseTrainer.train_step\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loader:\n\u001b[1;32m    661\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m set_inputs_to_device(inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 663\u001b[0m     model_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    665\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    666\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    667\u001b[0m \u001b[43m        \u001b[49m\u001b[43muses_ddp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistributed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    671\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizers_step(model_output)\n\u001b[1;32m    672\u001b[0m     loss \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    673\u001b[0m         model_output\u001b[38;5;241m.\u001b[39mloss_sum\n\u001b[1;32m    674\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model_output, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss_sum\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    675\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m model_output\u001b[38;5;241m.\u001b[39mloss\n\u001b[1;32m    676\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/dev/multivae_package/MultiVae/src/multivae/models/mhvae/mhvae_model.py:217\u001b[0m, in \u001b[0;36mMHVAE.forward\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    215\u001b[0m losses \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m subset \u001b[38;5;129;01min\u001b[39;00m subsets:\n\u001b[0;32m--> 217\u001b[0m     loss, kl_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_subset\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mz_Ls_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43mskips\u001b[49m\u001b[43m,\u001b[49m\u001b[43msubset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     losses\u001b[38;5;241m.\u001b[39mappend(loss)\n\u001b[1;32m    220\u001b[0m loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(losses)\u001b[38;5;241m.\u001b[39mmean() \u001b[38;5;66;03m# average on all subsets\u001b[39;00m\n",
      "File \u001b[0;32m~/dev/multivae_package/MultiVae/src/multivae/models/mhvae/mhvae_model.py:198\u001b[0m, in \u001b[0;36mMHVAE.loss_subset\u001b[0;34m(self, inputs, z_Ls_params, skips, subset)\u001b[0m\n\u001b[1;32m    195\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoders[mod](z_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mz_1\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    196\u001b[0m     recon \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mreconstruction\n\u001b[0;32m--> 198\u001b[0m     recon_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecon_log_probs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmod\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmod\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrescale_factors[mod]\n\u001b[1;32m    200\u001b[0m \u001b[38;5;66;03m# Sum all kls\u001b[39;00m\n\u001b[1;32m    201\u001b[0m kl \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/dev/multivae_package/MultiVae/src/multivae/models/base/base_ae_model.py:158\u001b[0m, in \u001b[0;36mBaseMultiVAE.set_decoders_dist.<locals>.<lambda>\u001b[0;34m(input, target)\u001b[0m\n\u001b[1;32m    156\u001b[0m     params_mod \u001b[38;5;241m=\u001b[39m dist_params_dict\u001b[38;5;241m.\u001b[39mpop(k, {})\n\u001b[1;32m    157\u001b[0m     scale \u001b[38;5;241m=\u001b[39m params_mod\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscale\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1.0\u001b[39m)\n\u001b[0;32m--> 158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecon_log_probs[k] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;28minput\u001b[39m, target: \u001b[43mdist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNormal\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mlog_prob(target)\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m recon_dict[k] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbernoulli\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecon_log_probs[k] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;28minput\u001b[39m, target: dist\u001b[38;5;241m.\u001b[39mBernoulli(\n\u001b[1;32m    164\u001b[0m         logits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28minput\u001b[39m\n\u001b[1;32m    165\u001b[0m     )\u001b[38;5;241m.\u001b[39mlog_prob(target)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/distributions/normal.py:54\u001b[0m, in \u001b[0;36mNormal.__init__\u001b[0;34m(self, loc, scale, validate_args)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, loc, scale, validate_args\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloc, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale \u001b[38;5;241m=\u001b[39m \u001b[43mbroadcast_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(loc, Number) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(scale, Number):\n\u001b[1;32m     56\u001b[0m         batch_shape \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mSize()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/distributions/utils.py:52\u001b[0m, in \u001b[0;36mbroadcast_all\u001b[0;34m(*values)\u001b[0m\n\u001b[1;32m     49\u001b[0m             options \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(dtype\u001b[38;5;241m=\u001b[39mvalue\u001b[38;5;241m.\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mvalue\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     50\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     51\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m---> 52\u001b[0m         v \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mis_tensor_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor(v, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m values\n\u001b[1;32m     53\u001b[0m     ]\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mbroadcast_tensors(\u001b[38;5;241m*\u001b[39mnew_values)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mbroadcast_tensors(\u001b[38;5;241m*\u001b[39mvalues)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/overrides.py:1958\u001b[0m, in \u001b[0;36mis_tensor_like\u001b[0;34m(inp)\u001b[0m\n\u001b[1;32m   1934\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1935\u001b[0m \u001b[38;5;124;03m    Returns True if the function passed in is a handler for a\u001b[39;00m\n\u001b[1;32m   1936\u001b[0m \u001b[38;5;124;03m    method or property belonging to ``torch.Tensor``, as passed\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1953\u001b[0m \u001b[38;5;124;03m    False\u001b[39;00m\n\u001b[1;32m   1954\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1955\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m _get_tensor_methods() \u001b[38;5;129;01mor\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__get__\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1958\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mis_tensor_like\u001b[39m(inp):\n\u001b[1;32m   1959\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1960\u001b[0m \u001b[38;5;124;03m    Returns ``True`` if the passed-in input is a Tensor-like.\u001b[39;00m\n\u001b[1;32m   1961\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1990\u001b[0m \u001b[38;5;124;03m    True\u001b[39;00m\n\u001b[1;32m   1991\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1992\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(inp) \u001b[38;5;129;01mis\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(inp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__torch_function__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from multivae.trainers import BaseTrainer, BaseTrainerConfig\n",
    "from multivae.trainers.base.callbacks import WandbCallback\n",
    "\n",
    "\n",
    "trainer_config = BaseTrainerConfig(\n",
    "    output_dir='~/experiments/mhvae_test',\n",
    "    per_device_eval_batch_size=64,\n",
    "    per_device_train_batch_size=64,\n",
    "    num_epochs=20,\n",
    "    steps_predict=1,\n",
    "    learning_rate=1e-3\n",
    "    )\n",
    "\n",
    "\n",
    "# wandb_cb = WandbCallback()\n",
    "# wandb_cb.setup(trainer_config,model_config,'mhvae_test')\n",
    "\n",
    "\n",
    "trainer = BaseTrainer(training_config=trainer_config,\n",
    "                      model=model,\n",
    "                      train_dataset=train_set,\n",
    "                      eval_dataset=eval_set,\n",
    "                    #   callbacks=[wandb_cb]\n",
    "                      )\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
